{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea6c1a-b427-43a4-8e7b-cffddf0ca479",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"numpy<2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011c9f3-58bb-4189-b8ee-30d80a5ee73f",
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e4568-e26d-4edb-b16f-7a696145b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_experimental.agent_toolkits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b34f87-8535-4af3-b414-7ea8bf2b4bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fac9612-f230-4259-8fe5-1a70f10c5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain: Document loading, splitting, and core schema\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader # Used if loading from files\n",
    "from langchain.text_splitter import CharacterTextSplitter # Used if splitting generic text\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "# Embeddings: OpenAI or HuggingFace\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings # Keep if using HF\n",
    "\n",
    "# Vector store: Chroma (Recommended Import)\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain.vectorstores import Chroma # Deprecated, can be removed if using the line above\n",
    "\n",
    "# Conversational memory and chain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# from langchain.retrievers.self_query.base import SelfQueryRetriever # Needed for Option 2\n",
    "from langchain.tools import Tool\n",
    "# from langchain.chains.query_constructor.base import AttributeInfo # Needed for Option 2\n",
    "\n",
    "# Visualization and analysis\n",
    "import matplotlib.pyplot as plt # Not used in recent steps, but maybe later\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # Only need one of these imports\n",
    "import urllib # Needed for quoting SQL connection parameters\n",
    "\n",
    "# Callbacks (Optional, for debugging)\n",
    "# from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "# OS utilities (Used for checking db path)\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbaa53d-4afe-4686-887a-bdafcd610058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"Medicines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49828431-91f7-48b0-83ab-defa0cced9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16aa0203-0502-4d0c-8427-9e1f236506d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DB: ChatbotFarmacia on localhost...\n",
      "Loading data...\n",
      "Successfully loaded 627 rows.\n",
      "Data split into 126 chunks.\n",
      "Attempting to connect to ChatbotFarmacia on localhost...\n",
      "Successfully connected to database 'ChatbotFarmacia' on 'localhost'.\n",
      "SQLAlchemy engine created.\n"
     ]
    }
   ],
   "source": [
    "# --- Database Connection Details ---\n",
    "SERVER_NAME = \"localhost\"\n",
    "DATABASE_NAME = \"ChatbotFarmacia\" # <-- Good, you've set your DB name\n",
    "TABLE_NAME = \"Medicines\" # Note: TABLE_NAME here isn't used for the engine itself\n",
    "SCHEMA_NAME = \"dbo\"      # Note: SCHEMA_NAME here isn't used for the engine itself\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "connection_string = f\"mssql+pyodbc://{SERVER_NAME}/{DATABASE_NAME}?driver={driver}&trusted_connection=yes\"\n",
    "\n",
    "\n",
    "# --- Create Engine & Load Data ---\n",
    "df = pd.DataFrame()\n",
    "chunks = []\n",
    "try:\n",
    "    print(f\"Connecting to DB: {DATABASE_NAME} on {SERVER_NAME}...\")\n",
    "    engine = create_engine(connection_string)\n",
    "    sql_query = f\"SELECT * FROM [dbo].[Medicines]\" # Or your relevant query\n",
    "    print(f\"Loading data...\")\n",
    "    df = pd.read_sql(sql_query, engine)\n",
    "    print(f\"Successfully loaded {len(df)} rows.\")\n",
    "\n",
    "    # --- Split DataFrame into Chunks ---\n",
    "    # This line creates the 'chunks' variable needed below\n",
    "    chunks = [df.iloc[i:i+5] for i in range(0, len(df), 5)]\n",
    "    print(f\"Data split into {len(chunks)} chunks.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data or creating chunks: {e}\")\n",
    "# --- Create Database Engine ---\n",
    "try:\n",
    "    print(f\"Attempting to connect to {DATABASE_NAME} on {SERVER_NAME}...\")\n",
    "    engine = create_engine(connection_string)\n",
    "    # Optional connection test\n",
    "    connection = engine.connect()\n",
    "    print(f\"Successfully connected to database '{DATABASE_NAME}' on '{SERVER_NAME}'.\")\n",
    "    connection.close()\n",
    "    print(\"SQLAlchemy engine created.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    # Handle error\n",
    "    exit()\n",
    "\n",
    "# --- The 'engine' variable created above is what you need for the SQL Agent ---\n",
    "\n",
    "include_tables = [\"Medicines\", \"inventory\", \"inventory_chorrera\", \"inventory_costa_del_este\", \"inventory_david\", \"inventory_el_dorado\", \"inventory_san_francisco\",  \"Stores\"] # List all tables\n",
    "db = SQLDatabase(engine=engine, schema=\"dbo\", include_tables=include_tables)\n",
    "# Optional: print(db.get_table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e355569e-ef05-4611-aae3-31cc52e863c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_tables = [\"Medicines\", \"inventory\", \"inventory_chorrera\", \"inventory_costa_del_este\", \"inventory_david\", \"inventory_el_dorado\", \"inventory_san_francisco\",  \"Stores\" ] # List all tables\n",
    "db = SQLDatabase(engine=engine, schema=\"dbo\", include_tables=include_tables)\n",
    "# Optional: print(db.get_table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "644935d4-e098-45bd-a3ca-686adca45a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Agent created successfully.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=MODEL, temperature=2) # Low temp recommended for agent logic\n",
    "\n",
    "# Add this import line, typically near the top with your other imports\n",
    "\n",
    "\n",
    "# --- Your existing code ---\n",
    "# llm = ChatOpenAI(...)\n",
    "# db = SQLDatabase(...)\n",
    "# --- End of existing code ---\n",
    "\n",
    "# Now you can create the agent (this line should work after the import)\n",
    "sql_agent = create_sql_agent(llm=llm, db=db, agent_type=\"openai-tools\", verbose=True) # Added verbose=True\n",
    "\n",
    "print(\"SQL Agent created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "289b7d59-0b62-45ad-ba85-e6a0657cd064",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_routing_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sql_agent \u001b[38;5;66;03m# Name of the agent variable for the SQL agent\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create the router agent using the router function\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m router_agent \u001b[38;5;241m=\u001b[39m create_routing_agent(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedicineAndInventoryRouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                    description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelects agent to query based on query content.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                    lifecycle\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     14\u001b[0m                                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_route\u001b[39m\u001b[38;5;124m\"\u001b[39m: router_function  \u001b[38;5;66;03m# The function we just defined\u001b[39;00m\n\u001b[0;32m     15\u001b[0m                                    })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_routing_agent' is not defined"
     ]
    }
   ],
   "source": [
    "# The router function takes the query, the currently running network (which includes the agents), and the network's state as input.\n",
    "# It should return the name of the agent to call next.\n",
    "def router_function(query, network):\n",
    "    # If the query contains keywords related to medicine, route to the vector search agent\n",
    "    if query.find(\"medicine\") or query.find(\"drugs\"):\n",
    "        return vector_search_agent # Name of the agent variable for the vector-based retriever\n",
    "    # Otherwise, route to the SQL agent for queries about stock and inventory\n",
    "    return sql_agent # Name of the agent variable for the SQL agent\n",
    "\n",
    "# Create the router agent using the router function\n",
    "router_agent = create_routing_agent(name=\"MedicineAndInventoryRouter\",\n",
    "                                   description=\"Selects agent to query based on query content.\",\n",
    "                                   lifecycle={\n",
    "                                       \"on_route\": router_function  # The function we just defined\n",
    "                                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef5937-ce13-4f6c-8020-56b3c746a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrected Document Creation Loop (Option 1) ---\n",
    "# Assuming 'chunks' is your list of DataFrames from the SQL query\n",
    "# Requires: from langchain.docstore.document import Document\n",
    "\n",
    "docs = []\n",
    "print(\"Starting document conversion (translating 1/0 status to text in page_content)...\")\n",
    "for i, chunk_df in enumerate(chunks):\n",
    "    for index, row in chunk_df.iterrows():\n",
    "        try:\n",
    "            # --- Get the numeric status (assuming column name is 'Prescription') ---\n",
    "            try:\n",
    "                 # Use the actual column name from your SQL table if different from 'Prescription'\n",
    "                 status_flag = int(row.get('Prescription', -1)) # Get 1, 0, or -1\n",
    "            except (ValueError, TypeError):\n",
    "                 status_flag = -1 # Handle non-numeric or missing data\n",
    "\n",
    "            # --- Translate numeric status to text ---\n",
    "            if status_flag == 1:\n",
    "                status_text = \"Requires Prescription\"\n",
    "            elif status_flag == 0:\n",
    "                status_text = \"Over-the-Counter\"\n",
    "            else:\n",
    "                status_text = \"Unknown\"\n",
    "\n",
    "            # --- MODIFIED page_content to include the status TEXT ---\n",
    "            # Use correct column names from your SQL table (e.g., 'Generic Name', 'Uses')\n",
    "            page_content = f\"Medicine: {row['Generic Name']}\\nUses: {row['Uses']}\\nPrescription Status: {status_text}\"\n",
    "\n",
    "            # --- Metadata: Store the numeric flag and other relevant fields ---\n",
    "            metadata = {\n",
    "                \"source_db_table\": f\"{SCHEMA_NAME}.{TABLE_NAME}\", # Identify source\n",
    "                # Use primary key from DB if available and useful, otherwise use index\n",
    "                # \"db_primary_key\": row.get('YourPrimaryKeyColumn'),\n",
    "                \"chunk_index\": i,\n",
    "                # Store the numeric flag using a clear key name\n",
    "                \"prescription_required_flag\": status_flag,\n",
    "                # Add other relevant fields from your DB table, ensuring column names match\n",
    "                \"uses\": row.get('Uses', \"\"),\n",
    "                \"side_effects_common\": row.get('Side Effects (Common)', \"\"),\n",
    "                \"side_effects_rare\": row.get('Side Effects (Rare)', \"\"),\n",
    "                \"similar_drugs\": row.get('Similar Drugs', \"\"),\n",
    "                \"brand_name_1\": row.get('Brand Name 1', \"\"),\n",
    "                # ... etc\n",
    "            }\n",
    "            docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError processing row {index}: {e} - Check column names from DB query!\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "print(f\"Created {len(docs)} Document objects with updated page_content.\")\n",
    "# --- End of Corrected Document Creation Loop ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d29aab-8fec-470f-b5cb-f10d8da39ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, view the first chunk\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a7c83-8fb9-41d5-9877-4b644f90120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings() # Assumes 'from langchain_openai import OpenAIEmbeddings' was used\n",
    "                               # and the OpenAI API key is configured (e.g., environment variable)\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "# Assumes 'db_name' variable (string path) is defined earlier\n",
    "# Assumes 'import os' and 'from langchain_chroma import Chroma' were used\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    try:\n",
    "        # Attempt to connect and delete the collection within the directory\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "        print(f\"Deleted existing collection in '{db_name}'.\")\n",
    "    except Exception as e:\n",
    "        # Handle cases where deletion might fail (e.g., directory exists but isn't a valid Chroma DB)\n",
    "        print(f\"Could not delete collection in '{db_name}': {e}\")\n",
    "\n",
    "# Create vectorstore\n",
    "# CRITICAL: Assumes 'docs' is a list of LangChain Document objects\n",
    "# It seems like 'docs' might still be undefined based on your previous error.\n",
    "# You need to convert your DataFrame chunks into Document objects first.\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, # 'docs' needs to be List[Document]\n",
    "                                     embedding=embeddings,\n",
    "                                     persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents in '{db_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abe597-e50f-4aff-9678-385496262bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ef209-d389-4e1c-b437-ed923bf4dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35183586-51e9-4860-9caa-dd78d2190c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings']) # Requires: import numpy as np\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "# doc_types = [metadata['doc_type'] for metadata in metadatas if metadata is not None] # REMOVED/COMMENTED\n",
    "# colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types] # REMOVED/COMMENTED\n",
    "\n",
    "# You can now work with vectors, documents, metadatas\n",
    "print(f\"Retrieved {len(vectors)} items.\")\n",
    "if metadatas:\n",
    "     print(\"First item metadata:\", metadatas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e5166-ed63-4562-8321-14d2848adced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume 'vectors' (numpy array) and 'documents' (list of strings) exist from collection.get()\n",
    "\n",
    "print(\"Running t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(vectors)-1)) # Added perplexity adjustment\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "print(\"t-SNE complete.\")\n",
    "\n",
    "# Create the 2D scatter plot (Simplified)\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8), # Removed 'color=colors'\n",
    "    # Simplified hover text using index and document snippet\n",
    "    text=[f\"Index: {i}<br>Text: {d[:100]}...\" for i, d in enumerate(documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization (t-SNE)',\n",
    "    xaxis_title='t-SNE Component 1', # More specific axis titles\n",
    "    yaxis_title='t-SNE Component 2',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3895426-abd2-434d-b48e-f3a66f0c5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume 'vectors', 'documents', 'metadatas' exist\n",
    "\n",
    "# --- Block to define colors (MUST RUN BEFORE PLOTTING) ---\n",
    "print(\"Defining colors based on metadata...\")\n",
    "status_list = [metadata.get('prescription_required', 'Unknown') for metadata in metadatas if metadata is not None]\n",
    "color_map = {'Prescription': 'red', 'Non-Prescription': 'blue', 'Unknown': 'grey'} # Adjust as needed\n",
    "colors = [color_map.get(status, 'grey') for status in status_list]\n",
    "print(\"Colors defined.\")\n",
    "# --- End of color definition block ---\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=min(30, len(vectors)-1))\n",
    "print(\"Running 3D t-SNE...\")\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "print(\"3D t-SNE complete.\")\n",
    "\n",
    "# Create the 3D scatter plot (Using defined colors and status_list)\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=3, color=colors, opacity=0.7), # Use defined 'colors'\n",
    "    # Update hover text\n",
    "    text=[f\"Prescription: {s}<br>Text: {d[:100]}...\" for s, d in zip(status_list, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization (t-SNE by Prescription Status)',\n",
    "    scene=dict(xaxis_title='t-SNE Comp 1', yaxis_title='t-SNE Comp 2', zaxis_title='t-SNE Comp 3'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f37cc-a9e6-41f8-b0f8-a209bc2bd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name as a string\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "# llm = ChatOpenAI(temperature=0.7, model_name='llama3.2', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975c79d-a1c7-49c6-9d6f-a6f869ef7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d359efe-07e9-4d0c-923e-24685c5d4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12554609-0002-4404-8636-7c5e01a1c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate what gets sent behind the scenes\n",
    "\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "query = \"What medications can you recommend for headaches?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e955ca-b612-495f-84a9-87592ef5fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG; k is how many chunks to use\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a380d9-cf0b-4785-8209-f944037ce2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4222e-b06e-4731-b687-ea876e57d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9431ab8-6af8-4ad0-894d-9241cfb3c1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
